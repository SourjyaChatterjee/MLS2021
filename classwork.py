# -*- coding: utf-8 -*-
"""ClassWork

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NYffiQQUokqcBT9XuMlvb4lOFXgFBEwZ
"""

!git clone https://github.com/YoongiKim/CIFAR-10-images

!ls

'''
from PIL import Image
import numpy as np
import os, os.path, time

format='.jpg'
myDir = "CIFAR-10-images"
def createFileList(myDir, format='.jpg'):
  fileList = []
  print(myDir)
  for root, dirs, files in os.walk(myDir, topdown=False):
    for name in files:
      if name.endswith(format):
        fullName = os.path.join(root, name)
      fileList.append(fullName)
  return fileList
  '''

#lst = createFileList("CIFAR-10-images/train", format)

#print(lst)

import os
p=[]
c=[]
for file_name in os.listdir("CIFAR-10-images/test/"):
  for files in os.listdir("CIFAR-10-images/test/"+file_name):
    if files.split(".")[-1].lower() in {"jpeg", "jpg", "png"}:
        #img = cv2.imread("CIFAR-10-images/test/airplane/0000.jpg" + file_name)
        #print('CIFAR-10-images/test/'+file_name+'/'+files, file_name)
        #dataset.append([['CIFAR-10-images/test/'+file_name+'/'+files , file_name]])
        path='CIFAR-10-images/test/'+file_name+'/'+files
        clss=file_name
        p.append(path)
        c.append(clss)


import pandas as pd
test_data=pd.DataFrame({'path':p,'clss':c})

test_data.head()

p=[]
c=[]
for file_name in os.listdir("CIFAR-10-images/train/"):
  for files in os.listdir("CIFAR-10-images/train/"+file_name):
    if files.split(".")[-1].lower() in {"jpeg", "jpg", "png"}:
        #img = cv2.imread("CIFAR-10-images/test/airplane/0000.jpg" + file_name)
        #print('CIFAR-10-images/test/'+file_name+'/'+files, file_name)
        #dataset.append([['CIFAR-10-images/test/'+file_name+'/'+files , file_name]])
        path='CIFAR-10-images/test/'+file_name+'/'+files
        clss=file_name
        p.append(path)
        c.append(clss)


import pandas as pd
train_data=pd.DataFrame({'path':p,'clss':c})
train_data.head()

import torch
import numpy as np

# check if CUDA is available
train_on_gpu = torch.cuda.is_available()

if not train_on_gpu:
    print('CUDA is not available.  Training on CPU ...')
else:
    print('CUDA is available!  Training on GPU ...')

from torchvision import datasets
import torchvision.transforms as transforms
from torch.utils.data.sampler import SubsetRandomSampler

"""**Data Augumentation**"""

transform = transforms.Compose([  
                                transforms.RandomHorizontalFlip(),
                                transforms.RandomRotation(15),
                                transforms.ToTensor(),
                                transforms.Normalize((.5,.5,.5),(.5,.5,.5))

])

data_dir = 'CIFAR-10-images'
train_data = datasets.ImageFolder(data_dir + '/train', transform=transforms)
test_data = datasets.ImageFolder(data_dir + '/test', transform=transforms)

"""**Data Loader**"""

'''
num_workers = 0
batch_size = 20
valid_size = 0.2


indices = list(range(len(train_data)))
np.random.shuffle(indices)
split = int(np.floor((valid_size * len(train_data))))
valid_idx , train_idx = indices[:split] , indices[split:]

train_sampler = SubsetRandomSampler(train_idx)
valid_sampler = SubsetRandomSampler(valid_idx)


train_loader = torch.utils.data.DataLoader(train_data , batch_size = batch_size, num_workers = num_workers , sampler = train_sampler)
valid_loader = torch.utils.data.DataLoader(train_data , batch_size = batch_size, num_workers = num_workers, sampler = valid_sampler)
test_loader = torch.utils.data.DataLoader(test_data , batch_size = batch_size , num_workers = num_workers)
'''

class MyDataset():
  def __init__(self,image_set,argument=True):
    with open(image_set,"r") as csv_handle:
      csv_reader = csv.reader(csv_handle,delimiter=",")
      self.imgfiles=[eachline[0] for eachline in csv_reader]
    self.argument=argument
  def __len__(self):
    return len(self.imgfiles)
  def __gititem__(self,idx):
    img=imageio.imread(self.imgfiles[idx])
    X=np.asarray(img,dtype=np.float32)
    if self.argument:
      X=do_yarn_transform(X)
    Y=self.classlabels[idx]
    return X,Y

'''
import matplotlib.pyplot as plt

dataiter = iter(train_loader)
images, labels = dataiter.next()
images = images.numpy() # convert images to numpy for display

plt.imshow(images[1])
'''



import torch.nn as nn
import torch.nn.functional as F

# define the CNN architecture
class CNN(nn.Module):
    def __init__(self):
        super().__init__()
        # convolutional layer (sees 32x32x3 image tensor)
        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)
        # convolutional layer (sees 16x16x16 tensor)
        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)
        # convolutional layer (sees 8x8x32 tensor)
        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)
        # max pooling layer
        self.pool = nn.MaxPool2d(2, 2)
        # linear layer (64 * 4 * 4 -> 500)
        self.fc1 = nn.Linear(64 * 4 * 4, 500)
        # linear layer (500 -> 10)
        self.fc2 = nn.Linear(500, 10)
        # dropout layer (p=0.25)
        self.dropout = nn.Dropout(0.25)

    def forward(self, x):
        # add sequence of convolutional and max pooling layers
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = self.pool(F.relu(self.conv3(x)))
        # flatten image input
        x = x.view(-1, 64 * 4 * 4)
        # add dropout layer
        x = self.dropout(x)
        # add 1st hidden layer, with relu activation function
        x = F.relu(self.fc1(x))
        # add dropout layer
        x = self.dropout(x)
        # add 2nd hidden layer, with relu activation function
        x = self.fc2(x)
        return x

# create a complete CNN
model_cnn = CNN()
print(model)

# move tensors to GPU if CUDA is available
if train_on_gpu:
    model.cuda()



"""**Define Loss and Solver**"""

import torch.optim as optim

# specify loss function (categorical cross-entropy)
criterion = nn.CrossEntropyLoss()

# specify optimizer
optimizer = optim.SGD(model.parameters(), lr=0.01)

"""**Train With Validation**"""

def Model_train(n_epoch, model, criterion, optimizer):
  valid_loss_min = np.Inf # track change in validation loss

  for epoch in range(1, n_epochs+1):

    # keep track of training and validation loss
    train_loss = 0.0
    valid_loss = 0.0
    
    ###################
    # train the model #
    ###################
    model.train()
    for batch_idx, (data, target) in enumerate(train_loader):
        # move tensors to GPU if CUDA is available
        if train_on_gpu:
            data, target = data.cuda(), target.cuda()
        # clear the gradients of all optimized variables
        optimizer.zero_grad()
        # forward pass: compute predicted outputs by passing inputs to the model
        output = model(data)
        # calculate the batch loss
        loss = criterion(output, target)
        # backward pass: compute gradient of the loss with respect to model parameters
        loss.backward()
        # perform a single optimization step (parameter update)
        optimizer.step()
        # update training loss
        train_loss += loss.item()*data.size(0)
        
    ######################    
    # validate the model #
    ######################
    model.eval()
    for batch_idx, (data, target) in enumerate(valid_loader):
        # move tensors to GPU if CUDA is available
        if train_on_gpu:
            data, target = data.cuda(), target.cuda()
        # forward pass: compute predicted outputs by passing inputs to the model
        output = model(data)
        # calculate the batch loss
        loss = criterion(output, target)
        # update average validation loss 
        valid_loss += loss.item()*data.size(0)
    
    # calculate average losses
    train_loss = train_loss/len(train_loader.sampler)
    valid_loss = valid_loss/len(valid_loader.sampler)
        
    # print training/validation statistics 
    print('Epoch: {} \tTraining Loss: {:.6f} \tValidation Loss: {:.6f}'.format(
        epoch, train_loss, valid_loss))
    
    # save model if validation loss has decreased
    if valid_loss <= valid_loss_min:
        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(
        valid_loss_min,
        valid_loss))
        torch.save(model.state_dict(), 'model_augmented.pt')
        valid_loss_min = valid_loss

Model_train(30 , model = model_cnn, criterion = criterion, optimizer = optimizer)